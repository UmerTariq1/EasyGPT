EasyGPT MVP: Technical Report

1. Architectural Overview
The proposed architecture follows a client-server model, separating the user interface (front-end) from the core logic and AI interactions (back-end).
Front-end (Streamlit): This component will handle all user interaction and the display of information. It will manage the conversation state using st.session_state and render the content in a custom, card-based format using a combination of Streamlit's native components and custom CSS.
Back-end (FastAPI): This component will be a lightweight API that serves a single, crucial purpose: to accept user queries, interact with the LLM API, and return a structured response. It will be the central hub for all LLM-related logic.
The two components will communicate via a single REST API endpoint. This design ensures that the front-end and back-end can be developed, tested, and deployed independently.

Why a Separate Backend is Necessary:
While a simple Streamlit app could make direct calls to the LLM API, this is not a recommended approach for a public-facing application due to significant security and scalability concerns.
Security: Placing the LLM API key in the front-end code (which is client-side) would expose it to anyone using the app. This is a major security risk that could lead to unauthorized use and unexpected costs. The FastAPI backend acts as a secure proxy, keeping the API key on the server where it cannot be accessed by the user.
Separation of Concerns: The backend holds the core business logic, such as prompt engineering and API key management. The front-end is solely responsible for the user interface. This separation makes the codebases cleaner, more maintainable, and easier to debug.
Scalability: A decoupled architecture allows the front-end and back-end to be scaled independently. If the app sees high user traffic, you can add more Streamlit instances. If API calls become a bottleneck, you can scale the FastAPI backend without affecting the front-end. This is essential for a product with growth potential.

2. High-Level Plan
Define a Structured Output Schema: The most important step is to design a clear JSON schema that the LLM will be prompted to follow. This is the foundation of the entire card-based UI.
Build the FastAPI Back-end: Create a single API endpoint that accepts a user prompt, calls the LLM with a system message and the user's prompt (with instructions to return JSON), and returns the parsed JSON response.
Build the Streamlit Front-end: Create a simple chat interface that sends user input to the FastAPI back-end and receives the JSON response. The front-end will then use this JSON data to dynamically generate a series of "cards" on the screen.
Add Custom CSS: Apply custom CSS to the Streamlit application to style the cards and other UI elements to match the "EasyGPT" product vision.

3. Core Logic: Handling Hierarchical Content and State
This is the most critical and complex part of the application. The goal is to present a single step to the user at a time, allowing them to navigate backward or forward, and ask clarifying questions that are in the context of the current step.

Implementation Strategy:
State Management with st.session_state: Streamlit's session state will be the central store for the entire conversation. Instead of just storing a list of messages, we will store a more complex data structure. This will include:
st.session_state.conversation_history: A full history of the user's initial prompts and the LLM's full, multi-card responses.
st.session_state.current_response_index: An integer that tracks which of the LLM's multi-card responses is currently being displayed.
st.session_state.current_card_index: An integer that tracks which card within the current multi-card response is being displayed.

User Actions and State Changes:
Initial Prompt: When a user enters a new prompt, the Streamlit app will call the FastAPI backend to get a full list of cards. This full response is then saved to st.session_state.conversation_history, and the current_response_index and current_card_index are reset to 0.
"Next" Button: A "Next" button will be displayed only if there are more cards in the current response. Clicking it will increment the st.session_state.current_card_index, triggering a rerun of the Streamlit app to show the next card.
"Back" Button: A "Back" button will be displayed if the current_card_index is greater than 0. Clicking it will decrement the index, showing the previous card.
Follow-up Question: When a user asks a follow-up question, the Streamlit app will need to send a new request to the backend. This request, however, won't just contain the new question. It will also include the text from the current card and a summary of overall context as additional context. This is crucial for guiding the LLM to provide a relevant and nested response.
Backend Logic for Follow-up Questions: The FastAPI backend will need a new API endpoint to handle clarifying questions. This endpoint would accept both the new prompt and the content of the current card. The prompt to the LLM would be carefully crafted to include this context.
Prompt Engineering for Context: The prompt to the LLM for a follow-up question would look something like this:
System Instruction: "You are a helpful assistant providing a clarifying response. The user has a question about a specific step. Your response should be a single, short paragraph that directly answers their question, referencing the provided context. Do not generate a new series of steps."
Context: The current step the user is on is: '{current_card_title}': '{current_card_content}'
User Question: '{user_followup_question}'

4. The Core UI Concept: The Card
The fundamental unit of the EasyGPT UI is the card. A card is a simple, clean, and self-contained container that holds a single piece of information, instruction, or a question. It is designed to be visually minimal and easy to process.

Main Screen: The user's screen will primarily show one card at a time. This eliminates the visual clutter of a long chat history and focuses the user's attention.
Simple Controls: Below the card, there will be clear, intuitive navigation buttons:
 "Next" to move to the next step or card.
 "Back" to return to the previous card.
 "View All" (or a similar option) to see the entire conversation or a list of all steps at once, catering to users who want a quick overview.
 A Contextual Input Box: At the bottom of the screen, there will be an input box. This isn't just for new queries. It's for asking questions about the specific content on the current card. This is a key feature that allows for a deeper, more focused conversation without losing the user's place in the main flow.

Hierarchical & Dynamic Flow  :
The UI isn't a static series of cards; it's dynamic and responsive to the user's needs.

Guided Instructions (Linear Path):

A user asks, "How do I make a grilled cheese sandwich?"

Card 1: Shows the title "Ingredients" and a list of items.
The user clicks "Next."
Card 2: Shows the title "Step 1: Preparation" and instructions like "butter the bread slices."
The user clicks "Next" or "Back" to navigate through the recipe, one step at a time.

Nested Conversations (Drilling Down):
The user is on the "Ingredients" card and asks, "What kind of cheese should I use?"
The UI displays the AI's response to that question within the context of that card, possibly in a smaller, nested pop-up or a temporary card that a user can dismiss to get back to the main flow. This keeps the user on the "Ingredients" step while they get the clarification they need.

Consultation Mode (Q&A):
A user asks, "What perfume should I buy?"
Card 1: The AI asks, "Do you prefer woody, floral, or fresh scents?" with maybe some quick-reply buttons.
The user selects an option.

Card 2: The AI asks the next clarifying question, "Is this for a day or evening occasion?" This continues in a focused, card-based Q&A format until the AI has enough information to provide a tailored recommendation.
Overall Aesthetic

Minimalist Design: Clean, uncluttered pages with a focus on a single content element at a time.
Large, Legible Text: To address the needs of older users, the font size will be easily adjustable and the typography will be clear and readable.
High Contrast: The color scheme will use high contrast to ensure readability for users with visual impairments.
Simple Visual Cues: Use icons and visual cues sparingly but effectively to guide the user without needing a lot of text. For example, a simple bread icon for a cooking recipe or a camera icon for a camera settings query.


5. File and Project Structure
A simple, extensible project structure is recommended for this MVP.
/easygpt-project
├──src / 
├──── /backend
│       ├── main.py        # FastAPI application and API endpoint
│       ├── schemas.py     # Pydantic models for request/response validation
│       └── requirements.txt # Dependencies for the back-end
├──── /frontend
│       ├── app.py         # Streamlit application and UI logic
│       ├── styles.css     # Custom CSS for the front-end
│       └── requirements.txt # Dependencies for the front-end
└─ .env               # Environment variables (e.g., API keys)



